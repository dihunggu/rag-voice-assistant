import os
import sqlite3
import requests
import streamlit as st
from dotenv import load_dotenv

# æ–°å¢å¼•ç”¨: STT/TTS å·¥å…·æ¨¡çµ„
import stt_tts_utils

load_dotenv()
st.set_page_config(page_title="API æ¸¬è©¦ UIï¼ˆRAG åŠ©ç† + èªéŸ³ï¼‰", layout="wide")

API_BASE = os.getenv("API_BASE", "http://127.0.0.1:8000")
DB_PATH = os.getenv("RAG_DB_PATH", "rag_admin.db")

# åˆå§‹åŒ– Google Clients (Lazy load or at startup)
@st.cache_resource
def get_google_clients():
    try:
        return stt_tts_utils.init_google_clients()
    except Exception as e:
        st.error(f"Google Cloud åˆå§‹åŒ–å¤±æ•—ï¼ˆå°‡ç„¡æ³•ä½¿ç”¨èªéŸ³åŠŸèƒ½ï¼‰: {e}")
        return None, None

speech_client, tts_client = get_google_clients()

@st.cache_resource
def get_openai_client():
    return stt_tts_utils.init_openai_client()

openai_client = get_openai_client()

def get_conn():
    conn = sqlite3.connect(DB_PATH, check_same_thread=False)
    conn.row_factory = sqlite3.Row
    return conn

def list_projects():
    try:
        conn = get_conn()
        rows = conn.execute(
            "SELECT project_id, project_name, vector_store_id FROM projects WHERE status='active' ORDER BY updated_at DESC"
        ).fetchall()
        return [dict(r) for r in rows]
    except Exception:
        # å¦‚æœä½ é‚„æ²’ç”¨ DBï¼Œä¹Ÿå¯ä»¥æ”¹æˆæ‰‹å‹•è¼¸å…¥ project_id / vector_store_id
        return []

st.title("API æ¸¬è©¦ (Text & Voice)")

with st.sidebar:
    st.header("è¨­å®š")
    st.text_input("API Base", value=API_BASE, key="api_base")
    st.text_input("User IDï¼ˆæ¸¬è©¦ç”¨ï¼‰", value="test-user-001", key="user_id")

    projects = list_projects()
    if projects:
        labels = [f"{p['project_name']} Â· {p['project_id'][:8]}" for p in projects]
        idx = st.selectbox("é¸æ“‡å°ˆæ¡ˆ", range(len(labels)), format_func=lambda i: labels[i])
        project_id = projects[idx]["project_id"]
        st.caption(f"project_id: {project_id}")
        st.caption(f"vector_store_id: {projects[idx]['vector_store_id']}")
    else:
        st.warning("æ‰¾ä¸åˆ° projectsï¼ˆè‹¥ä½ æ²’ç”¨ DBï¼šè«‹æ”¹æˆæ‰‹å‹•è¼¸å…¥ project_idï¼‰")
        project_id = st.text_input("project_id", value="")
    
    st.divider()
    st.header("èªéŸ³è¨­å®š")
    stt_provider = st.selectbox("STT/TTS æœå‹™å•†", ["Google", "OpenAI"], index=0)
    enable_voice_response = st.checkbox("å•Ÿç”¨ AI èªéŸ³å›æ‡‰ (TTS)", value=True)
    voice_language = st.selectbox("STT/TTS èªè¨€", ["zh-TW", "en-US"], index=0)

st.divider()

# Migrate history structure if needed (tuple -> dict)
if "history" not in st.session_state:
    st.session_state.history = []
else:
    # Quick fix for existing session state format compatibility
    new_history = []
    for item in st.session_state.history:
        if isinstance(item, tuple):
            new_history.append({"role": item[0], "content": item[1], "audio": None})
        elif isinstance(item, dict):
            new_history.append(item)
    st.session_state.history = new_history

# é¡¯ç¤ºæ­·å²
for msg in st.session_state.history:
    role = msg["role"]
    content = msg["content"]
    audio = msg.get("audio")
    
    with st.chat_message(role):
        st.markdown(content)
        if audio:
            st.audio(audio, format="audio/mp3")

# --------------------------
# è¼¸å…¥å€ï¼šæ”¯æ´ æ–‡å­— (`st.chat_input`) èˆ‡ èªéŸ³ (`st.audio_input`)
# --------------------------

# 1. èªéŸ³è¼¸å…¥
audio_prompt = None
if speech_client:
    # é€™è£¡ä½¿ç”¨ st.audio_input (Streamlit 1.40+)
    # è‹¥ç‰ˆæœ¬è¼ƒèˆŠå¯èƒ½æœƒå ±éŒ¯ï¼Œè«‹ user å‡ç´š
    audio_wav = st.audio_input("ğŸ¤ æŒ‰ä¸‹éŒ„éŸ³ç™¼å•")
    if audio_wav:
        # ç•¶æœ‰éŒ„éŸ³æ™‚ï¼Œé€²è¡Œ STT
        with st.spinner("èªéŸ³è¾¨è­˜ä¸­..."):
            audio_bytes = audio_wav.getvalue()
            # ç°¡å–®åšå€‹ cache check æ©Ÿåˆ¶é¿å…é‡è¤‡é€å‡º? 
            # Streamlit æ¯æ¬¡ rerun è‹¥ audio_wav æ²’è®Šï¼Œæœƒé‡è¤‡ process?
            # é€šå¸¸ st.audio_input åœ¨éŒ„è£½å®Œå¾Œæœƒè§¸ç™¼ rerunã€‚
            # ç‚ºäº†é¿å…åŒä¸€æ®µéŒ„éŸ³é‡è¤‡è§¸ç™¼ï¼Œå¯ä»¥åœ¨ session_state è¨˜ä½ä¸Šä¸€æ¬¡è™•ç†çš„ audio bytes
            
            # (é€™è£¡åšå€‹ç°¡æ˜“åˆ¤æ–·ï¼šè¨ˆç®— hash æˆ–ç›´æ¥æ¯”å° bytes)
            # ä½†ç‚ºäº†ç°¡å–®ï¼Œé€™è£¡å…ˆä¸åšéåº¦è¤‡é›œçš„é˜²å‘†ï¼Œå‡è¨­ä½¿ç”¨è€…éŒ„å®Œå°±æ˜¯æƒ³å•ã€‚
            # ä¸é Streamlit çš„ audio_input æœƒä¿ç•™ç‹€æ…‹ï¼Œç›´åˆ°é»å‰å‰ã€‚
            # æˆ‘å€‘éœ€è¦ä¸€å€‹æ©Ÿåˆ¶ä¾†åˆ¤æ–·ã€Œé€™æ˜¯æ–°éŒ„çš„ã€ã€‚
            pass # å¾Œé¢é‚è¼¯è™•ç†

# 2. æ–‡å­—è¼¸å…¥
text_prompt = st.chat_input("è¼¸å…¥å•é¡Œï¼ˆä¾‹å¦‚ï¼šè«‹åˆ—å‡ºç›®å‰å°ˆæ¡ˆ Top 3 é¢¨éšªä¸¦é™„å¼•ç”¨ï¼‰")

final_prompt = None
is_voice_input = False

# åˆ¤æ–·é‚è¼¯
if text_prompt:
    final_prompt = text_prompt
elif speech_client and audio_wav:
    # æª¢æŸ¥æ˜¯å¦å·²è™•ç†éé€™æ®µéŸ³è¨Š
    if "last_audio_bytes" not in st.session_state:
        st.session_state.last_audio_bytes = None
    
    current_audio_bytes = audio_wav.getvalue()
    if current_audio_bytes != st.session_state.last_audio_bytes:
        # é€™æ˜¯æ–°çš„éŒ„éŸ³ -> åŸ·è¡Œ STT
        # æ ¹æ“šé¸æ“‡çš„ Provider å‚³å…¥å°æ‡‰ Client
        # Google: speech_client, OpenAI: openai_client
        current_client = speech_client if stt_provider == "Google" else openai_client
        provider_code = stt_provider.lower()
        
        transcript = stt_tts_utils.speech_to_text(
            current_client, 
            current_audio_bytes, 
            provider=provider_code,
            language_code="cmn-Hant-TW" if voice_language=="zh-TW" else "en-US"
        )
        if transcript:
            final_prompt = transcript
            is_voice_input = True
            st.session_state.last_audio_bytes = current_audio_bytes
        else:
            st.warning("ç„¡æ³•è¾¨è­˜èªéŸ³ï¼Œè«‹é‡è©¦ã€‚")
    else:
        # é›–ç„¶æœ‰ audio_wavï¼Œä½†è·Ÿä¸Šæ¬¡ä¸€æ¨£ -> è¦–ç‚ºæ²’å‹•ä½œ (æˆ–ä½¿ç”¨è€…æœªæ¸…é™¤)
        pass

if final_prompt:
    # 1. é¡¯ç¤ºä½¿ç”¨è€…å•é¡Œ
    st.session_state.history.append({"role": "user", "content": final_prompt, "audio": None})
    with st.chat_message("user"):
        st.markdown(final_prompt)

    # 2. å‘¼å« RAG API
    payload = {
        "project_id": project_id,
        "message": final_prompt,
        "user_id": st.session_state.user_id
    }

    try:
        with st.chat_message("assistant"):
            with st.spinner("å‘¼å« API ä¸­..."):
                r = requests.post(f"{st.session_state.api_base}/chat", json=payload, timeout=60)
                r.raise_for_status()
                data = r.json()

            answer = data.get("answer", "")
            citations = data.get("citations", [])

            st.markdown(answer if answer else "(ç„¡å›è¦†)")

            if citations:
                st.markdown("#### å¼•ç”¨")
                for c in citations:
                    filename = c.get("filename", "(unknown)")
                    page = c.get("page")
                    quote = c.get("quote")
                    line = f"- {filename}"
                    if page is not None:
                        line += f"ï¼ˆp.{page}ï¼‰"
                    st.markdown(line)
                    if quote:
                        st.caption(quote)

            # 3. TTS (è‹¥å•Ÿç”¨)
            tts_audio = None
            if enable_voice_response and answer:
                # æ ¹æ“š Provider é¸æ“‡ Client
                # Google: tts_client, OpenAI: openai_client
                current_client = tts_client if stt_provider == "Google" else openai_client
                provider_code = stt_provider.lower()
                
                # è‹¥ client å­˜åœ¨æ‰åŸ·è¡Œ
                if current_client:
                    with st.spinner("ç”ŸæˆèªéŸ³ä¸­..."):
                        tts_audio = stt_tts_utils.text_to_speech(
                            current_client, 
                            answer, 
                            provider=provider_code, 
                            language_code=voice_language
                        )
                        if tts_audio:
                            st.audio(tts_audio, format="audio/mp3")

            st.session_state.history.append({
                "role": "assistant", 
                "content": answer if answer else "(ç„¡å›è¦†)",
                "audio": tts_audio
            })

    except Exception as e:
        err = f"API å‘¼å«å¤±æ•—ï¼š{e}"
        with st.chat_message("assistant"):
            st.error(err)
        st.session_state.history.append({"role": "assistant", "content": err, "audio": None})

